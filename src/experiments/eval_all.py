"""
All Strategies Evaluation

Baseline, DQN, PG ì „ëµë“¤ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ë¹„êµ
"""

import os
import sys
import json
import numpy as np
import pandas as pd
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, project_root)

from src.utils.data_loader import load_sp500_data, load_dgs10_data, preprocess_data, split_data
from src.env.portfolio_env import PortfolioEnv
from src.utils.metrics import calculate_all_metrics, print_metrics
from src.agents.dqn_agent import Qnet
from src.agents.pg_agent import PolicyNet, ValueNet
from src.config import (
    DATA_START_DATE, DATA_END_DATE,
    LAMBDA_RISK, EPISODE_YEARS,
    create_result_directories
)

import torch


class BaselineStrategy:
    """
    Baseline ì „ëµ í´ë˜ìŠ¤
    
    ê³ ì • ë¹„ì¤‘ ì „ëµ (ì£¼ì‹ 100%, ì±„ê¶Œ 100%, 60/40 ë“±)
    """
    
    def __init__(self, stock_weight, rebalance=False):
        """
        Args:
            stock_weight (float): ì£¼ì‹ ë¹„ì¤‘ (0.0~1.0)
            rebalance (bool): ì›”ì´ˆ ë¦¬ë°¸ëŸ°ì‹± ì—¬ë¶€
        """
        self.target_stock_weight = stock_weight
        self.rebalance = rebalance
        
        # ëª©í‘œ ë¹„ì¤‘ì— í•´ë‹¹í•˜ëŠ” ì•¡ì…˜ ì°¾ê¸°
        # action_values = [-1.0, -0.95, ..., 0, ..., 0.95, 1.0]
        # ì´ˆê¸° w_stock = 0.5ì´ë¯€ë¡œ, target - 0.5 = delta_w
        delta_w = stock_weight - 0.5
        
        # ê°€ì¥ ê°€ê¹Œìš´ ì•¡ì…˜ ì°¾ê¸°
        action_values = np.linspace(-1.0, 1.0, 41)
        self.action = np.argmin(np.abs(action_values - delta_w))
    
    def get_action(self, state):
        """
        ì•¡ì…˜ ì„ íƒ
        
        Args:
            state: í˜„ì¬ ìƒíƒœ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
            
        Returns:
            int: ì„ íƒëœ ì•¡ì…˜
        """
        if self.rebalance:
            # ë¦¬ë°¸ëŸ°ì‹±: í•­ìƒ ëª©í‘œ ë¹„ì¤‘ìœ¼ë¡œ ì¡°ì •
            return self.action
        else:
            # ë¦¬ë°¸ëŸ°ì‹± ì—†ìŒ: ì•¡ì…˜ 0 (ë³€í™” ì—†ìŒ)
            return 20  # action_values[20] = 0.0


def evaluate_baseline_simple(stock_weight, df, rebalance=False):
    """
    Baseline ì „ëµì„ ì§ì ‘ ê³„ì‚° (í™˜ê²½ ì—†ì´)
    
    Args:
        stock_weight (float): ì£¼ì‹ ë¹„ì¤‘ (0.0~1.0)
        df (pd.DataFrame): í‰ê°€ ë°ì´í„°
        rebalance (bool): ì›”ì´ˆ ë¦¬ë°¸ëŸ°ì‹± ì—¬ë¶€
        
    Returns:
        dict: ì„±ëŠ¥ ì§€í‘œ
    """
    w_stock = stock_weight
    w_bond = 1.0 - stock_weight
    
    returns = []
    prev_month = None
    
    for i in range(len(df)):
        # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
        r_portfolio = w_stock * df['r_stock'].iloc[i] + w_bond * df['r_bond'].iloc[i]
        returns.append(r_portfolio)
        
        # ì›”ì´ˆ ë¦¬ë°¸ëŸ°ì‹± (ì›”ì´ ë°”ë€Œì—ˆì„ ë•Œ)
        if rebalance:
            current_month = df.index[i].month
            if prev_month is not None and current_month != prev_month:
                # ì›”ì´ ë°”ë€œ â†’ ë¦¬ë°¸ëŸ°ì‹±
                w_stock = stock_weight
                w_bond = 1.0 - stock_weight
            prev_month = current_month
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    metrics = calculate_all_metrics(returns)
    
    return metrics


def compare_baselines(test_df):
    """
    Test ê¸°ê°„ì—ì„œ Baseline ì „ëµë“¤ ë¹„êµ
    
    Args:
        test_df: Test ë°ì´í„°
        
    Returns:
        dict: ê° ì „ëµì˜ ì„±ëŠ¥ ì§€í‘œ
    """
    print("=" * 70)
    print("Baseline Strategy Evaluation (Test Period)")
    print("=" * 70)
    print(f"Period: {test_df.index[0].date()} ~ {test_df.index[-1].date()}")
    print(f"Days: {len(test_df)}")
    print("=" * 70)
    
    # Baseline ì „ëµ ì •ì˜
    strategies = {
        '100% Stock': {'stock_weight': 1.0, 'rebalance': False},
        '100% Bond': {'stock_weight': 0.0, 'rebalance': False},
        '60/40 (Monthly Rebalance)': {'stock_weight': 0.6, 'rebalance': True}
    }
    
    results = {}
    
    for strategy_name, params in strategies.items():
        print(f"\n[{strategy_name}]")
        print("-" * 70)
        
        # ì „ëµ í‰ê°€
        metrics = evaluate_baseline_simple(
            stock_weight=params['stock_weight'],
            df=test_df,
            rebalance=params['rebalance']
        )
        
        # ê²°ê³¼ ì¶œë ¥
        print_metrics(metrics, title=strategy_name)
        
        # ê²°ê³¼ ì €ì¥
        results[strategy_name] = {
            'cumulative_return': metrics['cumulative_return'],
            'annualized_return': metrics['annualized_return'],
            'volatility': metrics['volatility'],
            'sharpe_ratio': metrics['sharpe_ratio'],
            'max_drawdown': metrics['max_drawdown'],
            'num_periods': metrics['num_periods']
        }
    
    return results


def evaluate_model(model, test_df, model_type='dqn'):
    """
    í•™ìŠµëœ ëª¨ë¸ì„ Test ë°ì´í„°ì—ì„œ í‰ê°€ (í™˜ê²½ ì—†ì´ ì§ì ‘ ê³„ì‚°)
    
    Args:
        model: í•™ìŠµëœ ëª¨ë¸ (Qnet ë˜ëŠ” PolicyNet)
        test_df: Test ë°ì´í„°í”„ë ˆì„
        model_type: 'dqn' ë˜ëŠ” 'pg'
        
    Returns:
        dict: ì„±ëŠ¥ ì§€í‘œ
    """
    model.eval()  # í‰ê°€ ëª¨ë“œ
    
    # ì´ˆê¸° ìƒíƒœ
    w_stock = 0.5
    w_bond = 0.5
    returns = []
    prev_month = None
    
    # ì•¡ì…˜ ê°’ ë°°ì—´ (í™˜ê²½ê³¼ ë™ì¼)
    action_values = np.linspace(-1.0, 1.0, 41)
    
    # ìµœì†Œ 5ì¼ ì´í›„ë¶€í„° ì‹œì‘ (ê³¼ê±° 5ì¼ ë°ì´í„° í•„ìš”)
    with torch.no_grad():
        for i in range(5, len(test_df)):
            # 1. ìƒíƒœ ìƒì„± (í™˜ê²½ì˜ _get_state()ì™€ ë™ì¼)
            r_stock_history = test_df['r_stock'].iloc[i-4:i+1].values  # 5ê°œ
            r_bond_history = test_df['r_bond'].iloc[i-4:i+1].values    # 5ê°œ
            
            state = np.concatenate([
                r_stock_history,  # 5ê°œ
                r_bond_history,   # 5ê°œ
                [w_stock]         # 1ê°œ
            ]).astype(np.float32)
            
            # 2. ëª¨ë¸ë¡œ ì•¡ì…˜ ì„ íƒ
            if model_type == 'dqn':
                state_tensor = torch.from_numpy(state).float().unsqueeze(0)
                q_values = model(state_tensor)
                action = q_values.argmax().item()
            else:  # pg
                action = model.act(state)
            
            # 3. ì•¡ì…˜ì„ delta_wë¡œ ë³€í™˜
            delta_w = action_values[action]
            
            # 4. ì›”ì´ˆ ë¦¬ë°¸ëŸ°ì‹± (í™˜ê²½ê³¼ ë™ì¼)
            current_month = test_df.index[i].month
            if prev_month is not None and current_month != prev_month:
                # ì›”ì´ ë°”ë€œ â†’ ë¦¬ë°¸ëŸ°ì‹±
                w_stock = np.clip(w_stock + delta_w, 0.0, 1.0)
                w_bond = 1.0 - w_stock
            prev_month = current_month
            
            # 5. í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
            r_portfolio = w_stock * test_df['r_stock'].iloc[i] + w_bond * test_df['r_bond'].iloc[i]
            returns.append(r_portfolio)
    
    # 6. ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    metrics = calculate_all_metrics(returns)
    return metrics


def load_and_evaluate_dqn(model_path, test_df):
    """
    DQN ëª¨ë¸ ë¡œë“œ ë° í‰ê°€
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        test_df: Test ë°ì´í„°
        
    Returns:
        dict: ì„±ëŠ¥ ì§€í‘œ
    """
    print("\n[DQN Model]")
    print("-" * 70)
    print(f"Loading model from: {model_path}")
    
    # ëª¨ë¸ ë¡œë“œ
    checkpoint = torch.load(model_path)
    model = Qnet()
    model.load_state_dict(checkpoint['q_state_dict'])
    
    # í‰ê°€ (í™˜ê²½ ì—†ì´ ì§ì ‘ ê³„ì‚°)
    metrics = evaluate_model(model, test_df, model_type='dqn')
    
    # ê²°ê³¼ ì¶œë ¥
    print_metrics(metrics, title="DQN Model")
    
    return {
        'cumulative_return': metrics['cumulative_return'],
        'annualized_return': metrics['annualized_return'],
        'volatility': metrics['volatility'],
        'sharpe_ratio': metrics['sharpe_ratio'],
        'max_drawdown': metrics['max_drawdown'],
        'num_periods': metrics['num_periods']
    }


def load_and_evaluate_pg(model_path, test_df):
    """
    PG ëª¨ë¸ ë¡œë“œ ë° í‰ê°€
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        test_df: Test ë°ì´í„°
        
    Returns:
        dict: ì„±ëŠ¥ ì§€í‘œ
    """
    print("\n[Policy Gradient Model]")
    print("-" * 70)
    print(f"Loading model from: {model_path}")
    
    # ëª¨ë¸ ë¡œë“œ
    checkpoint = torch.load(model_path)
    model = PolicyNet()
    model.load_state_dict(checkpoint['policy_state_dict'])
    
    # í‰ê°€ (í™˜ê²½ ì—†ì´ ì§ì ‘ ê³„ì‚°)
    metrics = evaluate_model(model, test_df, model_type='pg')
    
    # ê²°ê³¼ ì¶œë ¥
    print_metrics(metrics, title="Policy Gradient Model")
    
    return {
        'cumulative_return': metrics['cumulative_return'],
        'annualized_return': metrics['annualized_return'],
        'volatility': metrics['volatility'],
        'sharpe_ratio': metrics['sharpe_ratio'],
        'max_drawdown': metrics['max_drawdown'],
        'num_periods': metrics['num_periods']
    }


def compare_all_strategies(baseline_results, dqn_results, pg_results):
    """
    ëª¨ë“  ì „ëµ ë¹„êµ í…Œì´ë¸” ì¶œë ¥
    
    Args:
        baseline_results: Baseline ì „ëµ ê²°ê³¼
        dqn_results: DQN ê²°ê³¼
        pg_results: PG ê²°ê³¼
    """
    print("\n" + "=" * 70)
    print("All Strategies Comparison (Test Period)")
    print("=" * 70)
    
    # ëª¨ë“  ê²°ê³¼ í•©ì¹˜ê¸°
    all_results = {**baseline_results, 'DQN': dqn_results, 'Policy Gradient': pg_results}
    
    # í…Œì´ë¸” í—¤ë”
    print(f"\n{'Strategy':<30} {'Cum.Ret':<12} {'Ann.Ret':<10} {'Vol':<10} {'Sharpe':<10} {'MaxDD':<10}")
    print("-" * 90)
    
    # ê° ì „ëµ ì¶œë ¥
    for strategy_name, results in all_results.items():
        print(f"{strategy_name:<30} "
              f"{results['cumulative_return']:>10.2%}  "
              f"{results['annualized_return']:>8.2%}  "
              f"{results['volatility']:>8.2%}  "
              f"{results['sharpe_ratio']:>8.4f}  "
              f"{results['max_drawdown']:>8.2%}")
    
    print("=" * 90)
    
    # ìµœê³  Sharpe ratio ì°¾ê¸°
    best_strategy = max(all_results.items(), key=lambda x: x[1]['sharpe_ratio'])
    print(f"\nğŸ† Best Strategy (Sharpe Ratio): {best_strategy[0]} ({best_strategy[1]['sharpe_ratio']:.4f})")
    
    return all_results


def find_best_model(model_type='dqn'):
    """
    í•™ìŠµ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ ì°¾ê¸°
    
    Args:
        model_type: 'dqn' ë˜ëŠ” 'pg'
        
    Returns:
        str: ìµœê³  ì„±ëŠ¥ ëª¨ë¸ íŒŒì¼ëª…
    """
    logs_dir = os.path.join(project_root, 'results', 'logs')
    models_dir = os.path.join(project_root, 'results', 'models')
    
    # ë¡œê·¸ íŒŒì¼ ì°¾ê¸°
    log_files = [f for f in os.listdir(logs_dir) if f.startswith(f'{model_type}_training_log')]
    
    if not log_files:
        raise FileNotFoundError(f"No {model_type.upper()} training logs found")
    
    best_model = None
    best_performance = -float('inf')
    
    for log_file in log_files:
        log_path = os.path.join(logs_dir, log_file)
        
        with open(log_path, 'r') as f:
            training_log = json.load(f)
        
        # ë§ˆì§€ë§‰ Nê°œ ì—í”¼ì†Œë“œì˜ í‰ê·  reward ê³„ì‚°
        if model_type == 'dqn':
            # DQN: ë§ˆì§€ë§‰ 50 ì—í”¼ì†Œë“œ í‰ê· 
            recent_rewards = [episode['avg_reward'] for episode in training_log[-50:]]
        else:  # pg
            # PG: ë§ˆì§€ë§‰ 10 iteration í‰ê· 
            recent_rewards = [iteration['mean_return'] for iteration in training_log[-10:]]
        
        avg_performance = np.mean(recent_rewards)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°
        if avg_performance > best_performance:
            best_performance = avg_performance
            # ë¡œê·¸ íŒŒì¼ëª…ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
            timestamp = log_file.split('_')[-1].replace('.json', '')
            # í•´ë‹¹í•˜ëŠ” ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
            model_pattern = f"{model_type}_*_{timestamp}.pt"
            matching_models = [f for f in os.listdir(models_dir) if f.endswith(f'_{timestamp}.pt') and f.startswith(model_type)]
            if matching_models:
                best_model = matching_models[0]
    
    if best_model is None:
        raise FileNotFoundError(f"No matching {model_type.upper()} model found")
    
    print(f"Best {model_type.upper()} model: {best_model}")
    print(f"Average performance (last episodes): {best_performance:.4f}")
    
    return best_model


def save_results(results, filename='baseline_results.json'):
    """
    ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        results: í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        filename: ì €ì¥í•  íŒŒì¼ëª…
    """
    # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
    create_result_directories()
    
    # íŒŒì¼ ê²½ë¡œ
    filepath = os.path.join(project_root, 'results', 'logs', filename)
    
    # JSON ì €ì¥
    with open(filepath, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nâœ“ Results saved to: {filepath}")


def main():
    """
    ë©”ì¸ í•¨ìˆ˜
    """
    print("=" * 70)
    print("All Strategies Evaluation (Baseline + DQN + PG)")
    print("=" * 70)
    
    # ë°ì´í„° ë¡œë”©
    print("\n[Step 1/5] Loading data...")
    print("-" * 70)
    
    sp500_df = load_sp500_data(start_date=DATA_START_DATE, end_date=DATA_END_DATE)
    dgs10_df = load_dgs10_data()
    df = preprocess_data(sp500_df, dgs10_df)
    train_df, val_df, test_df = split_data(df)
    
    print("âœ“ Data loaded successfully!")
    print(f"  - Test: {len(test_df)} days ({test_df.index[0].date()} ~ {test_df.index[-1].date()})")
    
    # Baseline í‰ê°€ (Test ê¸°ê°„ë§Œ)
    print("\n[Step 2/5] Evaluating baseline strategies on Test set...")
    print("-" * 70)
    
    baseline_results = compare_baselines(test_df)
    
    # DQN í‰ê°€
    print("\n[Step 3/5] Evaluating DQN model on Test set...")
    print("-" * 70)
    
    # ìµœê³  ì„±ëŠ¥ DQN ëª¨ë¸ ì°¾ê¸°
    best_dqn_model = find_best_model('dqn')
    dqn_model_path = os.path.join(project_root, 'results', 'models', best_dqn_model)
    dqn_results = load_and_evaluate_dqn(dqn_model_path, test_df)
    
    # PG í‰ê°€
    print("\n[Step 4/5] Evaluating PG model on Test set...")
    print("-" * 70)
    
    # ìµœê³  ì„±ëŠ¥ PG ëª¨ë¸ ì°¾ê¸°
    best_pg_model = find_best_model('pg')
    pg_model_path = os.path.join(project_root, 'results', 'models', best_pg_model)
    pg_results = load_and_evaluate_pg(pg_model_path, test_df)
    
    # ëª¨ë“  ì „ëµ ë¹„êµ
    print("\n[Step 5/5] Comparing all strategies...")
    print("-" * 70)
    
    all_results = compare_all_strategies(baseline_results, dqn_results, pg_results)
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_results(all_results, filename=f'all_strategies_results_{timestamp}.json')
    
    print("\n" + "=" * 70)
    print("Evaluation Complete!")
    print("=" * 70)


if __name__ == '__main__':
    main()
